# -*- coding: utf-8 -*-
"""vision_transformer_experiment3_fine_tuning_with_plots.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vpqYtX50FM9-8VUo1xm1laf5y4aFEoSP
"""

import torch
#dataset link: https://www.robots.ox.ac.uk/~vgg/data/pets/ || https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz || https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz
from torchvision.datasets import OxfordIIITPet
import matplotlib.pyplot as plt
from random import random
from torchvision.transforms import Resize, ToTensor
from torchvision.transforms.functional import to_pil_image

to_tensor = [Resize((224, 224)), ToTensor()] #pre-processing

to_tensor

import torchvision
from torchvision import transforms
import PIL
transforms = [
    Resize((224, 224)),
    transforms.AutoAugment(),
    ToTensor()
]

print(transforms)

class Compose(object):
    def __init__(self, transforms):
        self.transforms = transforms

    def __call__(self, image, target):
        for t in self.transforms:
            image = t(image)
        return image, target

def show_images(images, num_samples=40, cols=8):
    """ Plots some samples from the dataset """
    plt.figure(figsize=(15,15))
    idx = int(len(dataset) / num_samples)
    print(images)
    for i, img in enumerate(images):
        if i % idx == 0:
            plt.subplot(int(num_samples/cols) + 1, cols, int(i/idx) + 1)
            plt.imshow(to_pil_image(img[0]))

dataset = OxfordIIITPet(root=".", download=True, transforms=Compose(to_tensor))
# show_images(dataset)

from torchvision.models import vit_b_16

from torch.utils.data import DataLoader
from torch.utils.data import random_split

train_split = int(0.8 * len(dataset))
train, test = random_split(dataset, [train_split, len(dataset) - train_split])

train_dataloader = DataLoader(train, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test, batch_size=32, shuffle=True)

print(len(train))
print(len(test))

import torch.optim as optim
from torch import nn
from torch import Tensor
import numpy as np


device = "cuda"

# class Net(nn.Module):
#     def __init__(self):
#         super(Net, self).__init__()
#         self.model = vit_b_16(weights='IMAGENET1K_V1')
#         for param in self.model.parameters():
#              param.requires_grad = False
#         self.model.heads = nn.Linear(768, 37)
#         self.model.heads.weight.data.normal_(mean=0.5, std=0.5)
#         self.model.heads.bias.data.zero_()
#     def forward(self, x: torch.Tensor):
#         x = self.model(x)
#         return x
loss_values = []
test_loss_values = []

model = vit_b_16(weights='IMAGENET1K_V1')
for param in model.parameters():
    param.requires_grad = False
model.heads = nn.Linear(768, 37)

model.to(device)

optimizer = optim.AdamW(model.parameters(), lr=0.01, betas=(0.9, 0.999), weight_decay = 0.1)
criterion = nn.CrossEntropyLoss()

test_loss = 10
best_loss = 10

# #use for the test loss calculation
# epoch_losses_test = []

for epoch in range(10):
    epoch_losses = []
    model.train()
    for step, (inputs, labels) in enumerate(train_dataloader):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss_values.append(loss)
        loss.backward()
        optimizer.step()

        #get training loss values
        epoch_losses.append(loss.item())


        #calculating training loss
    print(f">>> Epoch {epoch} train loss: ", np.mean(epoch_losses))

    # #get the last_test_lost
    # last_test_loss = np.mean(epoch_losses_test)

    #initialize for this one
    epoch_losses_test = []

    model.eval()

    for step, (inputs, labels) in enumerate(test_dataloader):
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)


        #get this test lost values
        epoch_losses_test.append(loss.item())

    #calculating testloss
    test_loss = np.mean(epoch_losses_test)
    test_loss_values.append(test_loss)

    print(f">>> Epoch {epoch} test loss: ", test_loss)

    #saving files
    if(best_loss > test_loss):
          torch.save(model.state_dict(), 'best.pth')
          torch.save(model, 'model_best.pth')
          print("Model saved best ckpt")
          best_loss = test_loss

    torch.save(model.state_dict(), 'last.pth')
    torch.save(model, 'model_last.pth')
    print("Model saved last ckpt")

import matplotlib.pyplot as plt
for i in range(len(loss_values)):
    loss_values[i] = loss_values[i].item()

for i in range(len(test_loss_values)):
    test_loss_values[i] = test_loss_values[i].item()

plt.plot(test_loss_values, label='test loss')
plt.legend()
plt.show()

plt.plot(loss_values, label='train loss')
plt.legend()
plt.show()

model.eval()
inputs, labels = next(iter(train_dataloader))
inputs, labels = inputs.to(device), labels.to(device)
outputs = model(inputs)


print("Predicted classes", outputs.argmax(-1))
print("Actual classes", labels)

inputs, labels = next(iter(test_dataloader))
inputs, labels = inputs.to(device), labels.to(device)
outputs = model(inputs)


print("Predicted classes", outputs.argmax(-1))
print("Actual classes", labels)

model.load_state_dict(torch.load('best.pth'))
inputs, labels = next(iter(train_dataloader))
inputs, labels = inputs.to(device), labels.to(device)
outputs = model(inputs)


print("Predicted classes", outputs.argmax(-1))
print("Actual classes", labels)

inputs, labels = next(iter(test_dataloader))
inputs, labels = inputs.to(device), labels.to(device)
outputs = model(inputs)


print("Predicted classes", outputs.argmax(-1)[0])
print("Actual classes", labels)

inference = OxfordIIITPet(root=".", split='test', download=True, transforms=Compose(to_tensor))

print(len(inference))

inference_dataloader = DataLoader(inference, batch_size=32, shuffle=True)

len(inference_dataloader)

print(labels[0])

correct = 0
for step, (inputs, labels) in enumerate(inference_dataloader):
    inputs, labels = inputs.to(device), labels.to(device)
    outputs = model(inputs)
    length = len(labels)

    for i in range(length):
        output = outputs.argmax(-1)[i]
        label = labels[i]
        if output == label:
            correct += 1

print(f"Inference Accuracy: {correct/len(inference)}")

inputs, labels = next(iter(inference_dataloader))
inputs, labels = inputs.to(device), labels.to(device)
outputs = model(inputs)

print("Predicted classes", outputs.argmax(-1))
print("Actual classes", labels)

# confusion matrix
from sklearn.metrics import confusion_matrix

y_pred = []
y_true = []
model.to('cpu')
for step, (inputs, labels) in enumerate(inference_dataloader):
    inputs, labels = inputs.to('cpu'), labels.to('cpu')
    outputs = model(inputs)
    length = len(labels)

    for i in range(length):
        output = outputs.argmax(-1)[i]
        label = labels[i]
        y_pred.append(output)
        y_true.append(label)

cm = confusion_matrix(y_true, y_pred)



plt.imshow(confusion_matrix(y_true, y_pred))