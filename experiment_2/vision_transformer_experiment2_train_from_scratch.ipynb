{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-3VfzTCAXq1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#dataset link: https://www.robots.ox.ac.uk/~vgg/data/pets/ || https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz || https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torchvision.transforms.functional import to_pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km65HLMfBiS5"
      },
      "outputs": [],
      "source": [
        "to_tensor = [Resize((224, 224)), ToTensor()] #pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwWKf8JjNchO",
        "outputId": "a524c718-3d15-4689-b62e-a4bdd1e1b73f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn),\n",
              " ToTensor()]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "to_tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import PIL\n",
        "transforms = [\n",
        "    Resize((224, 224)),\n",
        "    # transforms.RandomCrop(50, padding=1),\n",
        "    # transforms.RandomGrayscale(p=0.1),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(20),\n",
        "    # transforms.RandomRotation(degrees=(0, 20)),\n",
        "    transforms.AutoAugment(),\n",
        "    ToTensor()\n",
        "]"
      ],
      "metadata": {
        "id": "aGVNVte9f_M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nbJGgsNm2GM",
        "outputId": "090e4282-583b-4fed-e78b-05230754237d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn), AutoAugment(policy=AutoAugmentPolicy.IMAGENET, fill=None), ToTensor()]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDYz3QOZB5qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a857b5-831a-44c0-83c5-c3cdd22bbd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 791918971/791918971 [00:06<00:00, 126405530.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting oxford-iiit-pet/images.tar.gz to oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19173078/19173078 [00:00<00:00, 112132641.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting oxford-iiit-pet/annotations.tar.gz to oxford-iiit-pet\n"
          ]
        }
      ],
      "source": [
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image = t(image)\n",
        "        return image, target\n",
        "\n",
        "def show_images(images, num_samples=40, cols=8):\n",
        "    \"\"\" Plots some samples from the dataset \"\"\"\n",
        "    plt.figure(figsize=(15,15))\n",
        "    idx = int(len(dataset) / num_samples)\n",
        "    print(images)\n",
        "    for i, img in enumerate(images):\n",
        "        if i % idx == 0:\n",
        "            plt.subplot(int(num_samples/cols) + 1, cols, int(i/idx) + 1)\n",
        "            plt.imshow(to_pil_image(img[0]))\n",
        "\n",
        "dataset = OxfordIIITPet(root=\".\", download=True, transforms=Compose(to_tensor))\n",
        "# new_dataset = OxfordIIITPet(root=\".\", download=True, transforms=Compose(transforms))\n",
        "\n",
        "# show_images(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytMyRTOJ5pVi"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import vit_b_16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_YEmEKRUKON"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_split = int(0.8 * len(dataset))\n",
        "train, test = random_split(dataset, [train_split, len(dataset) - train_split])\n",
        "\n",
        "train_dataloader = DataLoader(train, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Won4l7kUM_F",
        "outputId": "6feb14ce-b871-48fc-c6f0-4578ba125c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Epoch 0 train loss:  13.156557899454366\n",
            ">>> Epoch 0 test loss:  4.871868237205174\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 5 train loss:  3.8151700418928396\n",
            ">>> Epoch 5 test loss:  3.761606962784477\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 10 train loss:  3.6614993292352427\n",
            ">>> Epoch 10 test loss:  3.635543325672979\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 15 train loss:  3.6319891007050225\n",
            ">>> Epoch 15 test loss:  3.6253922089286474\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 20 train loss:  3.6005941836730293\n",
            ">>> Epoch 20 test loss:  3.61181902885437\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 25 train loss:  3.571427239024121\n",
            ">>> Epoch 25 test loss:  3.5922998760057534\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 30 train loss:  3.550463943377785\n",
            ">>> Epoch 30 test loss:  3.5587729889413584\n",
            "Model saved best ckpt\n",
            "Model saved last ckpt\n",
            ">>> Epoch 35 train loss:  3.5353263953457708\n",
            ">>> Epoch 35 test loss:  3.6058873715608017\n",
            "Model saved last ckpt\n",
            ">>> Epoch 40 train loss:  3.5543449495149697\n",
            ">>> Epoch 40 test loss:  3.5608260942542036\n",
            "Model saved last ckpt\n",
            ">>> Epoch 45 train loss:  3.58184189900108\n",
            ">>> Epoch 45 test loss:  3.597303628921509\n",
            "Model saved last ckpt\n",
            ">>> Epoch 50 train loss:  3.5944418518439583\n",
            ">>> Epoch 50 test loss:  3.6437836833622144\n",
            "Model saved last ckpt\n",
            ">>> Epoch 55 train loss:  3.602573389592378\n",
            ">>> Epoch 55 test loss:  3.6312487954678745\n",
            "Model saved last ckpt\n",
            ">>> Epoch 60 train loss:  3.573041400183802\n",
            ">>> Epoch 60 test loss:  3.6175921481588613\n",
            "Model saved last ckpt\n",
            ">>> Epoch 65 train loss:  3.574281358200571\n",
            ">>> Epoch 65 test loss:  3.6589725950489873\n",
            "Model saved last ckpt\n",
            ">>> Epoch 70 train loss:  3.589133723922398\n",
            ">>> Epoch 70 test loss:  3.6233646247697915\n",
            "Model saved last ckpt\n",
            ">>> Epoch 75 train loss:  3.600299594194993\n",
            ">>> Epoch 75 test loss:  3.6340917089711064\n",
            "Model saved last ckpt\n",
            ">>> Epoch 80 train loss:  3.5802267064218936\n",
            ">>> Epoch 80 test loss:  3.5972029229869014\n",
            "Model saved last ckpt\n",
            ">>> Epoch 85 train loss:  3.592766883580581\n",
            ">>> Epoch 85 test loss:  3.609623131544694\n",
            "Model saved last ckpt\n",
            ">>> Epoch 90 train loss:  3.5699104796285215\n",
            ">>> Epoch 90 test loss:  3.6452412086984385\n",
            "Model saved last ckpt\n",
            ">>> Epoch 95 train loss:  3.5752747680829917\n",
            ">>> Epoch 95 test loss:  3.6272072895713476\n",
            "Model saved last ckpt\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = vit_b_16(weights='DEFAULT')\n",
        "        self.model.heads = nn.Linear(768, 37)\n",
        "        self.model.heads.weight.data.normal_(mean=0.5, std=0.5)\n",
        "        self.model.heads.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "            # Reshape and permute the input tensor\n",
        "            x = self.model._process_input(x)\n",
        "            n = x.shape[0]\n",
        "\n",
        "            # Expand the class token to the full batch\n",
        "            batch_class_token = self.model.class_token.expand(n, -1, -1)\n",
        "            x = torch.cat([batch_class_token, x], dim=1)\n",
        "\n",
        "            x = self.model.encoder(x)\n",
        "\n",
        "            # Classifier \"token\" as used by standard language architectures\n",
        "            x = x[:, 0]\n",
        "\n",
        "            x = self.model.heads(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "model = Net().to(device)\n",
        "# print(model)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.01, betas=(0.9, 0.999), weight_decay = 0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "test_loss = 10\n",
        "best_loss = 10\n",
        "\n",
        "# #use for the test loss calculation\n",
        "# epoch_losses_test = []\n",
        "\n",
        "for epoch in range(100):\n",
        "    epoch_losses = []\n",
        "    model.train()\n",
        "    for step, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #get training loss values\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        #calculating training loss\n",
        "        print(f\">>> Epoch {epoch} train loss: \", np.mean(epoch_losses))\n",
        "\n",
        "        # #get the last_test_lost\n",
        "        # last_test_loss = np.mean(epoch_losses_test)\n",
        "\n",
        "        #initialize for this one\n",
        "        epoch_losses_test = []\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        for step, (inputs, labels) in enumerate(test_dataloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            #get this test lost values\n",
        "            epoch_losses_test.append(loss.item())\n",
        "\n",
        "        #calculating testloss\n",
        "        test_loss = np.mean(epoch_losses_test)\n",
        "\n",
        "        print(f\">>> Epoch {epoch} test loss: \", test_loss)\n",
        "\n",
        "        #saving files\n",
        "        if(best_loss > test_loss):\n",
        "              torch.save(model.state_dict(), 'best.pth')\n",
        "              torch.save(model, 'model_best.pth')\n",
        "              print(\"Model saved best ckpt\")\n",
        "              best_loss = test_loss\n",
        "\n",
        "        torch.save(model.state_dict(), 'last.pth')\n",
        "        torch.save(model, 'model_last.pth')\n",
        "        print(\"Model saved last ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "inputs, labels = next(iter(train_dataloader))\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "outputs = model(inputs)\n",
        "\n",
        "\n",
        "print(\"Predicted classes\", outputs.argmax(-1))\n",
        "print(\"Actual classes\", labels)"
      ],
      "metadata": {
        "id": "ihX2qIAUOywr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e838c3e-5861-4ee5-83ea-ef1a57090d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes tensor([22, 31, 31, 31, 22, 31, 31, 31,  3,  3, 31, 22,  0, 31, 22, 22, 22, 31,\n",
            "        31,  3, 31, 31, 31, 22, 22, 31, 31, 22, 22, 31, 22,  3],\n",
            "       device='cuda:0')\n",
            "Actual classes tensor([27, 22,  6, 14,  9,  0, 26, 23,  1, 20, 23, 15,  9, 12, 12, 29, 11, 14,\n",
            "        35,  7, 17,  5, 13,  3, 34, 30, 15, 26, 28,  1, 24, 33],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, labels = next(iter(test_dataloader))\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "outputs = model(inputs)\n",
        "\n",
        "\n",
        "print(\"Predicted classes\", outputs.argmax(-1))\n",
        "print(\"Actual classes\", labels)"
      ],
      "metadata": {
        "id": "leOSQUx60guy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ebbcae-e19a-43cd-eb03-045f53f5907c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes tensor([27, 22, 22, 31, 31, 31,  3,  3, 22,  0, 22, 31, 22, 22,  3, 22, 22,  3,\n",
            "        22, 27, 22, 22, 31, 31, 22, 31, 31, 31, 31, 31, 22, 31],\n",
            "       device='cuda:0')\n",
            "Actual classes tensor([13, 29,  4, 20, 13, 20, 15,  2,  2, 14,  0, 35, 16, 13, 33, 29, 10, 14,\n",
            "        34, 36, 22, 10, 17, 14, 18, 16, 14, 19, 25, 20, 28,  9],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best.pth'))\n",
        "inputs, labels = next(iter(train_dataloader))\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "outputs = model(inputs)\n",
        "\n",
        "\n",
        "print(\"Predicted classes\", outputs.argmax(-1))\n",
        "print(\"Actual classes\", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEQkEDIMysSv",
        "outputId": "65933177-4f8f-45b0-ab03-7f61ce96ebbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes tensor([18, 34, 34, 34, 34, 34, 27, 34, 34,  7,  7,  3,  0, 18,  3,  3,  7,  7,\n",
            "        23, 34, 18,  7,  7,  3,  3,  0,  7,  0, 18,  3, 17, 18],\n",
            "       device='cuda:0')\n",
            "Actual classes tensor([27, 27, 30,  9,  8, 18, 10, 34, 23,  3,  4, 20, 16, 18,  7,  8,  7,  6,\n",
            "        22,  8,  3,  4, 12,  6, 29, 16, 17, 12, 10, 22, 34, 16],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, labels = next(iter(test_dataloader))\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "outputs = model(inputs)\n",
        "\n",
        "\n",
        "print(\"Predicted classes\", outputs.argmax(-1))\n",
        "print(\"Actual classes\", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiJSqujry4g8",
        "outputId": "b4eba129-52e3-480a-8564-3fb9ee83cd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes tensor([23, 17,  3,  0, 18, 34,  0,  3,  0, 18, 34, 34,  3,  7,  7, 34, 34, 34,\n",
            "        34,  3,  7, 34, 34,  3, 23, 27, 17, 34, 18, 17,  0, 18],\n",
            "       device='cuda:0')\n",
            "Actual classes tensor([21, 10,  2, 16, 31, 32, 11, 28, 34, 18,  5, 19, 33, 15, 16,  8, 21,  0,\n",
            "         2, 12, 24, 20, 34, 10, 31, 12,  6, 35, 10, 14, 24, 27],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}